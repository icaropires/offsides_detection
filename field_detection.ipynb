{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "\n",
    "def show_img(img, size=(15, 15)):\n",
    "    plt.figure(figsize=size)\n",
    "    \n",
    "    if len(img.shape) == 2:\n",
    "        plt.gray()\n",
    "        plt.imshow(img)\n",
    "    else:\n",
    "        plt.imshow(img[:, :, ::-1])\n",
    "    plt.show()\n",
    "    \n",
    "def play_video(video_path, f = lambda x: x, frames=-1, window_name='Video', fps=30, **kwargs):\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if vidcap.isOpened():\n",
    "        length = vidcap.get(cv2.CAP_PROP_FRAME_COUNT) if frames == -1 else frames\n",
    "        success,img = vidcap.read()\n",
    "\n",
    "        old_frame, k, counter = img, -1, 0\n",
    "        while success and counter != frames and k != ord('q'):\n",
    "            old_frame = img\n",
    "            cv2.imshow(window_name, f(img, **kwargs))\n",
    "\n",
    "            sleep(1/fps)\n",
    "            success, img = vidcap.read()\n",
    "            k = cv2.waitKey(1)\n",
    "            counter += 1\n",
    "\n",
    "            pos = int(counter/length * 90)\n",
    "            print('Playing video: ' + '[' + pos*'o' + '>' + ' '*(90 - pos) + ']', end='\\r')\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "        vidcap.release()\n",
    "    else:\n",
    "        print(\"Couldn't open the video!\")\n",
    "    \n",
    "    return old_frame    \n",
    "\n",
    "def get_gray(img):\n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)    \n",
    "\n",
    "# Colored images as input\n",
    "def whitefy(img, b_threshold=70, g_threshold=127, r_threshold=100, bright=20):\n",
    "    B, G, R = cv2.split(img)\n",
    "    \n",
    "    _, B = cv2.threshold(B, b_threshold, 255, cv2.THRESH_BINARY)\n",
    "    _, G = cv2.threshold(G, g_threshold, 255, cv2.THRESH_BINARY)\n",
    "    _, R = cv2.threshold(R, r_threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    mask = cv2.bitwise_and(cv2.bitwise_and(B, G), R)\n",
    "    \n",
    "    bright = np.ones(img.shape, dtype=np.uint8) * bright\n",
    "    bright = cv2.bitwise_and(bright, bright, mask=mask)\n",
    "    \n",
    "    return img + bright\n",
    "\n",
    "# WIP\n",
    "def whitefy_best_green(img, b_threshold=70, g_threshold=127, r_threshold=100, bright=20, c=1):\n",
    "    B, G, R = cv2.split(img)\n",
    "    best_green, best_green2 = np.int8(G > B*(1+c/10)), np.int8(G > R*(1+c/10))\n",
    "    best_green = np.int16(cv2.bitwise_and(best_green, best_green, mask=best_green2))*10\n",
    "    \n",
    "    _, B = cv2.threshold(B, b_threshold, 255, cv2.THRESH_BINARY)\n",
    "    _, G = cv2.threshold(G, g_threshold, 255, cv2.THRESH_BINARY)\n",
    "    _, R = cv2.threshold(R, r_threshold, 255, cv2.THRESH_BINARY)\n",
    "    _, best_green = cv2.threshold(best_green, 1, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    mask = cv2.bitwise_and(cv2.bitwise_and(B, G),R)\n",
    "    best_green_and_white = cv2.bitwise_and(best_green, best_green, mask=mask)\n",
    "    \n",
    "    bright = np.ones(img.shape, dtype=np.uint8) * bright\n",
    "    bright = cv2.bitwise_and(bright, bright, mask=mask)\n",
    "    \n",
    "    return best_green_and_white\n",
    "\n",
    "def get_edges_with_diff(img, se_1=2, se_2=2, shape_idx=0, iterations_erode=1, iterations_dilate=1):\n",
    "    shape = (cv2.MORPH_ELLIPSE, cv2.MORPH_CROSS, cv2.MORPH_RECT)\n",
    "    se = cv2.getStructuringElement(shape[shape_idx%len(shape)], (se_1, se_2))\n",
    "    \n",
    "    img_prev = cv2.erode(img, se, iterations=iterations_erode)\n",
    "    img = cv2.dilate(img, se, iterations=iterations_dilate)\n",
    "    \n",
    "    return img - img_prev\n",
    "\n",
    "def erode(img, se_1=2, se_2=2, shape_idx=0, iterations=1):\n",
    "    shape = (cv2.MORPH_ELLIPSE, cv2.MORPH_CROSS, cv2.MORPH_RECT)\n",
    "    se = cv2.getStructuringElement(shape[shape_idx%len(shape)], (se_1, se_2))\n",
    "\n",
    "    return cv2.erode(img, se, iterations=iterations)\n",
    "\n",
    "def dilate(img, se_1=2, se_2=2, shape_idx=0, iterations=1):\n",
    "    shape = (cv2.MORPH_ELLIPSE, cv2.MORPH_CROSS, cv2.MORPH_RECT)\n",
    "    se = cv2.getStructuringElement(shape[shape_idx%len(shape)], (se_1, se_2))\n",
    "\n",
    "    return cv2.dilate(img, se, iterations=iterations)\n",
    "    \n",
    "def calibrate(img, f, args, range_min=0, range_max=255, title='calibrating'):\n",
    "    cv2.imshow(title, img)\n",
    "    \n",
    "    for arg in args:\n",
    "        cv2.createTrackbar(arg, title, range_min, range_max, lambda x : x)\n",
    "        \n",
    "    new_img, k = img, -1\n",
    "    while k != ord('q'):\n",
    "        cv2.imshow(title, new_img)\n",
    "        new_kwargs = {k: v for k,v in ((arg, cv2.getTrackbarPos(arg, title)) for arg in args)}\n",
    "        new_img = f(img, **new_kwargs)\n",
    "        k = cv2.waitKey(1)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "def show_lines(img, img_orig):\n",
    "    lines = cv2.HoughLinesP(img, 1,np.pi/180,200, minLineLength=100, maxLineGap=5)\n",
    "    for line in lines:\n",
    "        x1,y1,x2,y2 = line[0]\n",
    "        cv2.line(img_orig,(x1,y1),(x2,y2),(210,247,1),2)\n",
    "    return img_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Playing video: [oooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooooo>]\r"
     ]
    }
   ],
   "source": [
    "def treatment(img, lines=False):\n",
    "    img_orig = img\n",
    "    img = whitefy(img_orig)\n",
    "    img = get_gray(img)\n",
    "    img = cv2.Canny(img, 100, 200, True)\n",
    "    img = get_edges_with_diff(img)\n",
    "    \n",
    "    img = dilate(img, se_1=2, se_2=2, shape_idx=0, iterations=3)\n",
    "    #img = cv2.blur(img, (4, 4))\n",
    "    img = erode(img, shape_idx=0, se_1=1, se_2=2, iterations=5)\n",
    "    #img = cv2.Canny(img, 100, 200, True, apertureSize=3)\n",
    "\n",
    "    if lines:\n",
    "        show_lines(img, img_orig)\n",
    "        return img_orig\n",
    "    return img\n",
    "\n",
    "for i in range(21, 22):\n",
    "    i = 23\n",
    "    play_video(f'../samples_offside/sample{i}.mp4', f=treatment, frames=-1, lines=True)\n",
    "    play_video(f'../samples_offside/sample{i}.mp4', f=treatment, frames=-1, lines=False)\n",
    "    break\n",
    "\n",
    "# img2 = play_video('../samples_offside/sample21.mp4', frames=1)\n",
    "# calibrate(img2, whitefy, ('b_threshold', 'g_threshold', 'r_threshold', 'c'), title='whitefy')\n",
    "\n",
    "#img_processed = treatment(img)\n",
    "#show_img(img_processed)\n",
    "\n",
    "#calibrate(img_processed, whitefy, ('b_threshold', 'g_threshold', 'r_threshold', 'c'), title='whitefy')\n",
    "# calibrate(img, cv2.Canny, ('threshold1', 'threshold2'), title='canny')\n",
    "# calibrate(img, get_edges_with_diff, ('se_1', 'se_2', 'iterations_erode', 'iterations_dilate', 'shape_idx'), 2, 20, title='edges')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
